# ==============================================================================
# ğŸ“ ì‚¬ì „ ì¤€ë¹„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° API í‚¤ ì„¤ì •
# ==============================================================================
import google.generativeai as genai
import pandas as pd
import json
import os
import time
import re
import logging
import numpy as np

# âœ¨ ê²½ë¡œ ì„¤ì •
PATH = './data/dongwon/'
os.makedirs(PATH, exist_ok=True)
# âœ¨ ì¶”ê°€: í˜ë¥´ì†Œë‚˜ JSON íŒŒì¼ì„ ì €ì¥í•  ìºì‹œ í´ë” ìƒì„±
PERSONA_CACHE_PATH = os.path.join(PATH, 'personas')
os.makedirs(PERSONA_CACHE_PATH, exist_ok=True)

# ğŸªµ ======================= ë¡œê±° ì„¤ì • ======================= ğŸªµ
timestamp = time.strftime("%Y%m%d_%H%M%S")
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

if not logger.handlers:
    stream_handler = logging.StreamHandler()
    stream_handler.setFormatter(formatter)
    logger.addHandler(stream_handler)

    log_filename = os.path.join(PATH, f'final_log_{timestamp}.log')
    file_handler = logging.FileHandler(log_filename, encoding='utf-8')
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)

logger.info("âœ… ë¡œê¹… ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
# ğŸªµ =============================================================== ğŸªµ

# â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­
# âœ¨ 0. ì‹¤í–‰ ëª¨ë“œ ì„¤ì • (ê°€ì¥ ì¤‘ìš”í•œ ë¶€ë¶„!)
# ------------------------------------------------------------------------------
# True : APIë¥¼ í˜¸ì¶œí•˜ì—¬ í˜ë¥´ì†Œë‚˜ë¥¼ 'ìƒˆë¡œ ìƒì„±'í•˜ê³  JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤. (ì‹œê°„/ë¹„ìš© ë°œìƒ)
# False: ê¸°ì¡´ì— ì €ì¥ëœ JSON íŒŒì¼ì„ 'ë¶ˆëŸ¬ì™€ì„œ' ì‚¬ìš©í•©ë‹ˆë‹¤. (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©, API í˜¸ì¶œ X)
# ------------------------------------------------------------------------------
# USE_API_TO_GENERATE_PERSONAS = True
USE_API_TO_GENERATE_PERSONAS = False
# â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­â­

# [ì¤‘ìš”] ì‚¬ìš©ìì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
# (API ëª¨ë“œê°€ Falseì¼ ê²½ìš°, ì´ ë¶€ë¶„ì€ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
if USE_API_TO_GENERATE_PERSONAS:
    try:
        # -------------------------------------------------------------------------
        # genai.configure(api_key="ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")
        # -------------------------------------------------------------------------
        genai.configure(api_key="") # <--- âš ï¸ ì—¬ê¸°ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
        model = genai.GenerativeModel('models/gemini-2.0-flash') # ëª¨ë¸ëª…ì€ ìµœì‹  ë²„ì „ìœ¼ë¡œ ìœ ì§€í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.
        logger.info("âœ… Gemini API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤. [API ëª¨ë“œ]")
    except Exception as e:
        logger.error(f"â—ï¸ API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        # API í‚¤ê°€ ì—†ìœ¼ë©´ API ëª¨ë“œë¥¼ ê°•ì œë¡œ ë¹„í™œì„±í™”
        USE_API_TO_GENERATE_PERSONAS = False
        logger.warning("â—ï¸ API ì‚¬ìš©ì´ ë¶ˆê°€ëŠ¥í•˜ì—¬ [ìºì‹œ ì‚¬ìš© ëª¨ë“œ]ë¡œ ê°•ì œ ì „í™˜í•©ë‹ˆë‹¤.")

# í—¬í¼ í•¨ìˆ˜
def extract_json_from_response(text):
    match = re.search(r'```json\s*(\[.*\])\s*```', text, re.DOTALL)
    if match:
        return match.group(1)
    match = re.search(r'\[.*\]', text, re.DOTALL)
    if match:
        return match.group(0)
    return None

# âœ¨ ì¶”ê°€: íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì•ˆì „í•œ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def sanitize_filename(name):
    """ì œí’ˆëª…ì—ì„œ íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë¥¼ '_'ë¡œ ë³€ê²½í•©ë‹ˆë‹¤."""
    return re.sub(r'[\\/*?:"<>|]', '_', name)

# ==============================================================================
# âœ¨ 1. í˜ë¥´ì†Œë‚˜ ìƒì„± í”„ë¡¬í”„íŠ¸ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
def create_product_specific_prompt(product_name, num_personas=30):
    # (ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼)
    target_customer_profile = "ì¼ë°˜ì ì¸ ëŒ€í•œë¯¼êµ­ ì†Œë¹„ì"
    if 'í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸' in product_name:
        target_customer_profile = "20-40ëŒ€ ì—¬ì„±ìœ¼ë¡œ, ê±´ê°•ê³¼ ìê¸°ê´€ë¦¬ì— ê´€ì‹¬ì´ ë§ê³ , ì†Œë“ ìˆ˜ì¤€ì€ ì¤‘ìƒ ì´ìƒì¸ 1ì¸ ê°€êµ¬. ì£¼ë¡œ ì˜¨ë¼ì¸ ì±„ë„ì„ í†µí•´ ê±´ê°•ì‹í’ˆì„ êµ¬ë§¤í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ."
    elif 'ë§›ì°¸' in product_name:
        target_customer_profile = "20-40ëŒ€ ë‚¨ë…€ë¡œ, í¸ì˜ì„±ê³¼ ìƒˆë¡œìš´ ë§›ì„ ì¶”êµ¬í•˜ë©° ìœ íŠœë¸Œ, ì¸ìŠ¤íƒ€ê·¸ë¨ ë“± ì†Œì…œ ë¯¸ë””ì–´ì— ìµìˆ™í•˜ê³  í¸ì˜ì ì´ë‚˜ ì˜¨ë¼ì¸ì—ì„œ ê°„í¸í•˜ê²Œ ì‹ì‚¬ë¥¼ í•´ê²°í•˜ë ¤ëŠ” 1ì¸ ê°€êµ¬ í•™ìƒ ë° ì§ì¥ì¸. 30-50ëŒ€ ì£¼ë¶€ë¡œ, 3ì¸ ì´ìƒ ê°€êµ¬ì˜ ì‹ì‚¬ë¥¼ ì±…ì„ì§€ê³  ìˆìŒ. ëŒ€í˜•ë§ˆíŠ¸ì—ì„œ ì¥ì„ ë³´ë©°, ëª…ì ˆ ë“± íŠ¹ë³„í•œ ë‚ ì— ê°€ì¡±ì„ ìœ„í•œ ìš”ë¦¬ë¥¼ ì¤€ë¹„í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•¨."
        if 'ë§¤ì½¤' in product_name:
            target_customer_profile += " íŠ¹íˆ ë§¤ìš´ë§›ì„ ì„ í˜¸í•˜ëŠ” ê²½í–¥ì´ ëšœë ·í•¨."
    elif 'ë¦¬ì±”' in product_name:
        target_customer_profile = "30-50ëŒ€ ì£¼ë¶€ë¡œ, 3ì¸ ì´ìƒ ê°€êµ¬ì˜ ì‹ì‚¬ë¥¼ ì±…ì„ì§€ê³  ìˆìŒ. ëŒ€í˜•ë§ˆíŠ¸ì—ì„œ ì¥ì„ ë³´ë©°, ëª…ì ˆ ë“± íŠ¹ë³„í•œ ë‚ ì— ê°€ì¡±ì„ ìœ„í•œ ìš”ë¦¬ë¥¼ ì¤€ë¹„í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•¨."
    elif 'ì°¸ì¹˜ì•¡' in product_name:
        target_customer_profile = "ìš”ë¦¬ì— ê´€ì‹¬ì´ ë§ì€ 30-60ëŒ€ ì£¼ë¶€ ë˜ëŠ” 1ì¸ ê°€êµ¬. ì§‘ë°¥ì„ ì„ í˜¸í•˜ë©°, ìŒì‹ì˜ ê¹Šì€ ë§›ì„ ë‚´ê¸° ìœ„í•œ ì¡°ë¯¸ë£Œì— íˆ¬ìë¥¼ ì•„ë¼ì§€ ì•ŠìŒ. ëŒ€í˜•ë§ˆíŠ¸ì™€ ì˜¨ë¼ì¸ ì±„ë„ì„ ëª¨ë‘ ì´ìš©í•¨."
        if 'ì§„' in product_name or 'í”„ë¦¬ë¯¸ì—„' in product_name:
            target_customer_profile += " íŠ¹íˆ ìš”ë¦¬ ì‹¤ë ¥ì´ ë›°ì–´ë‚˜ê³ , ì†Œë“ ìˆ˜ì¤€ì´ ë†’ì•„ í”„ë¦¬ë¯¸ì—„ ì œí’ˆì„ ì„ í˜¸í•˜ëŠ” ë¯¸ì‹ê°€ì  ì„±í–¥ì„ ë³´ì„."
    elif 'ì†Œí™”ê°€ ì˜ë˜ëŠ”' in product_name:
        target_customer_profile = "ìœ ë‹¹ë¶ˆë‚´ì¦ì´ ìˆê±°ë‚˜ ì†Œí™” ê±´ê°•ì— ì‹ ê²½ ì“°ëŠ” 20-50ëŒ€. ê±´ê°•ì„ ìœ„í•´ ì¼ë°˜ ìœ ì œí’ˆ ëŒ€ì‹  ë½í† í”„ë¦¬ ì œí’ˆì„ ì„ íƒí•˜ë©°, ì¶œê·¼ê¸¸ì´ë‚˜ ì ì‹¬ì‹œê°„ì— í¸ì˜ì ì—ì„œ ìì£¼ êµ¬ë§¤í•¨."
        if 'ë°”ë‹ë¼ë¼ë–¼' in product_name:
            target_customer_profile += " ë‹¨ë§›ì„ ì„ í˜¸í•˜ëŠ” ì Šì€ ì¸µì˜ ë¹„ì¤‘ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ."
    logger.info(f" ğŸ¯ íƒ€ê²Ÿ í”„ë¡œí•„ ì„¤ì •: {target_customer_profile}")
    prompt = f"""
    ë‹¹ì‹ ì€ íŠ¹ì • ì œí’ˆì˜ í•µì‹¬ êµ¬ë§¤ ê³ ê° í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ëŠ” ë§ˆì¼€íŒ… ë¶„ì„ AIì…ë‹ˆë‹¤.
    [ì§€ì‹œì‚¬í•­]
    1.  **ì„ë¬´**: ì•„ë˜ [ì œí’ˆ ì •ë³´]ì— ëª…ì‹œëœ ì œí’ˆì„ êµ¬ë§¤í•  ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ì€ **í•µì‹¬ ê³ ê° í˜ë¥´ì†Œë‚˜ {num_personas}ê°œ**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    2.  **í•µì‹¬ ì¡°ê±´**: ìƒì„±ë˜ëŠ” í˜ë¥´ì†Œë‚˜ëŠ” ì•„ë˜ [íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„]ì˜ íŠ¹ì„±ì„ ì§‘ì¤‘ì ìœ¼ë¡œ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤. í˜ë¥´ì†Œë‚˜ì˜ ëª¨ë“  ì†ì„±ì€ ì´ í”„ë¡œí•„ê³¼ ë…¼ë¦¬ì ìœ¼ë¡œ ê°•ë ¥í•˜ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    3.  **ì¶œë ¥**: ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]ë¥¼ ì™„ë²½íˆ ë”°ë¥´ëŠ” ë‹¨ì¼ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”. JSONì€ ë°˜ë“œì‹œ ```json ... ``` ì½”ë“œ ë¸”ë¡ ì•ˆì— í¬í•¨ì‹œì¼œ ì£¼ì„¸ìš”.
    [ì œí’ˆ ì •ë³´]
    - ì œí’ˆëª…: "{product_name}"
    [íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„]
    - {target_customer_profile}
    [ì†ì„± ê°€ì´ë“œ]
    - `age`: "10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"
    - `gender`: "ë‚¨ì„±", "ì—¬ì„±"
    - `occupation`: "ì§ì¥ì¸", "í•™ìƒ", "ì£¼ë¶€", "í”„ë¦¬ëœì„œ", "ìì˜ì—…ì", "ë¬´ì§", "ì€í‡´"
    - `income_level`: "ìƒ", "ì¤‘ìƒ", "ì¤‘", "ì¤‘í•˜", "í•˜"
    - `household_size`: "1ì¸ ê°€êµ¬", "2ì¸ ê°€êµ¬", "3ì¸ ê°€êµ¬", "4ì¸ ê°€êµ¬ ì´ìƒ"
    - `lifestyle`: "ê±´ê°•ì§€í–¥", "ìê¸°ê´€ë¦¬", "í¸ì˜ì„±ì¶”êµ¬", "ê°€ì„±ë¹„ì¤‘ì‹œ", "íŠ¸ë Œë“œì¶”êµ¬", "ìš”ë¦¬ì• í˜¸ê°€", "ì§‘ë°¥ì„ í˜¸", "ë¯¸ì‹ê°€"
    - `media_consumption`: ["YouTube", "Instagram", "TV", "ì»¤ë®¤ë‹ˆí‹°ì‚¬ì´íŠ¸"] ë“±
    - `price_sensitivity`: "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
    - `brand_loyalty`: "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
    - `dietary_preferences`: "ê³ ë‹¨ë°±", "ì €ì¹¼ë¡œë¦¬", "ìœ ë‹¹ë¶ˆë‚´ì¦ì¼€ì–´", "ì†Œí™”í¸í•œìŒì‹ì„ í˜¸", "ë§¤ìš´ë§›ì„ í˜¸" ë“±
    - `shopping_channel`: "ëŒ€í˜•ë§ˆíŠ¸", "ì˜¨ë¼ì¸", "í¸ì˜ì ", "ë°±í™”ì "
    [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
    ```json
    [
      {{
        "persona_id": "P00001", "attributes": {{"age": "30ëŒ€", "gender": "ì—¬ì„±", "occupation": "ì§ì¥ì¸", "income_level": "ì¤‘ìƒ", "household_size": "1ì¸ ê°€êµ¬", "lifestyle": "ê±´ê°•ì§€í–¥", "media_consumption": ["YouTube", "Instagram"], "price_sensitivity": "ì¤‘ê°„", "brand_loyalty": "ë‚®ìŒ", "dietary_preferences": "ê³ ë‹¨ë°±", "shopping_channel": "ì˜¨ë¼ì¸"}}, "purchase_probability": 0.85, "base_purchase_frequency_per_month": 4.0, "monthly_propensity_modifier": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
      }}
    ]
    ```
    """
    return prompt

logger.info("âœ… 1. í˜ë¥´ì†Œë‚˜ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================================================================
# âœ¨ 2. ì—ì´ì „íŠ¸ ë° ì‹œì¥ ì‹œë®¬ë ˆì´ì…˜ í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
class PersonaAgent:
    def __init__(self, persona_data):
        self.id = persona_data.get('persona_id', 'N/A')
        self.attributes = persona_data.get('attributes', {})
        self.base_purchase_rate = persona_data.get('base_purchase_frequency_per_month', 0) / 30.0
        self.state = 'Unaware'
        self.p_churn = 0.05

    def update_state(self, p_innovation, p_imitation, adoption_rate):
        if self.state == 'Unaware':
            prob_aware = p_innovation + p_imitation * adoption_rate
            if np.random.rand() < prob_aware:
                self.state = 'Active'
        elif self.state == 'Active':
            if np.random.rand() < self.p_churn:
                self.state = 'Churned'

    def attempt_purchase(self, month_modifier):
        if self.state == 'Active':
            monthly_purchase_prob = (1 - (1 - self.base_purchase_rate)**30) * month_modifier
            if np.random.rand() < monthly_purchase_prob:
                return 1
        return 0

class MarketSimulation:
    def __init__(self, personas, tam, market_share, modifiers, initial_adoption_rate=0.1):
        self.agents = [PersonaAgent(p) for p in personas if p]
        self.potential_market_size = int(tam * market_share)
        self.modifiers = modifiers
        self.p_innovation = 0.01
        self.q_imitation = 0.38
        
        num_initial_adopters = int(len(self.agents) * initial_adoption_rate)
        np.random.shuffle(self.agents)
        for i in range(num_initial_adopters):
            if i < len(self.agents):
                self.agents[i].state = 'Active'
        
        self.adopters = int(self.potential_market_size * initial_adoption_rate)
        logger.info(f"   - ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘. ì´ˆê¸° ì±„íƒë¥ : {initial_adoption_rate*100:.1f}%, ì´ˆê¸° í™œì„± ê³ ê° ìˆ˜(ì¶”ì •): {self.adopters}")

    def run_simulation(self, months=12):
        monthly_sales_results = []
        num_agents = len(self.agents)

        if num_agents == 0:
            logger.warning("âš ï¸ ì—ì´ì „íŠ¸ê°€ ì—†ì–´ ì‹œë®¬ë ˆì´ì…˜ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 0ì„ ë°˜í™˜í•©ë‹ˆë‹¤.")
            return [0] * months

        for month_index in range(months):
            adoption_rate = self.adopters / self.potential_market_size if self.potential_market_size > 0 else 0
            
            current_month_sales = 0
            active_agents_count = 0
            
            for agent in self.agents:
                agent.update_state(self.p_innovation, self.q_imitation, adoption_rate)
                month_modifier = self.modifiers[month_index]
                current_month_sales += agent.attempt_purchase(month_modifier)
                if agent.state == 'Active':
                    active_agents_count += 1
            
            sample_purchase_rate = current_month_sales / num_agents if num_agents > 0 else 0
            extrapolated_sales = sample_purchase_rate * self.potential_market_size
            monthly_sales_results.append(int(extrapolated_sales))
            
            self.adopters = (active_agents_count / num_agents) * self.potential_market_size if num_agents > 0 else 0

        return monthly_sales_results

logger.info("âœ… 2. ì‹œë®¬ë ˆì´ì…˜ í´ë˜ìŠ¤ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================================================================
# âœ¨ 3. ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„° ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
ESTABLISHED_PRODUCTS = [
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 135g', 'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 90g', 'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 135g', 'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 90g',
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 500g', 'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 900g', 'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 500g', 'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 900g',
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 500g', 'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 900g'
]

NEW_PRODUCT_LAUNCH_DATES = {
    'ë´ë§ˆí¬ í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸ 400g': (2025, 2),
    'ë¦¬ì±” ì˜¤ë¯ˆë ˆí–„ 200g': (2025, 5),
    'ë¦¬ì±” ì˜¤ë¯ˆë ˆí–„ 340g': (2025, 5),
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ë°”ë‹ë¼ë¼ë–¼ 250mL': (2025, 2),
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ì¹´í˜ë¼ë–¼ 250mL': (2025, 2)
}
logger.info("âœ… 3-1. ê¸°ì¡´/ì‹ ì œí’ˆ ì •ë³´ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")

HOLIDAY_MODIFIERS = {
    'seollal_chuseok': [1.8, 5.5, 1.0, 0.9, 1.0, 1.1, 1.2, 2.5, 6.5, 1.0, 1.0, 1.1],
    'seollal_chuseok_sub': [1.3, 3.0, 1.0, 1.1, 1.2, 1.1, 1.2, 1.8, 3.5, 1.1, 1.0, 1.3]
}
DEFAULT_MODIFIERS = [1.0] * 12
SIMULATION_PARAMS = {
    'ë´ë§ˆí¬ í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸ 400g': {'tam': 6000000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.2, 1.4, 1.4, 1.3, 1.2, 1.2, 0.9, 0.8, 0.7, 0.7]},
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 135g': {'tam': 20000000, 'market_share': 0.07, 'modifiers': [0.9, 0.8, 1.2, 1.2, 1.2, 1.1, 1.2, 1.3, 0.9, 1.1, 1.0, 1.1]},
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 90g':  {'tam': 20000000, 'market_share': 0.05, 'modifiers': [0.9, 0.8, 1.2, 1.2, 1.2, 1.1, 1.2, 1.3, 0.9, 1.1, 1.0, 1.1]},
    'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 135g': {'tam': 20000000, 'market_share': 0.05, 'modifiers': [0.9, 0.8, 1.2, 1.2, 1.2, 1.1, 1.2, 1.3, 0.9, 1.1, 1.0, 1.1]},
    'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 90g':  {'tam': 20000000, 'market_share': 0.03, 'modifiers': [0.9, 0.8, 1.2, 1.2, 1.2, 1.1, 1.2, 1.3, 0.9, 1.1, 1.0, 1.1]},
    'ë¦¬ì±” ì˜¤ë¯ˆë ˆí–„ 200g': {'tam': 3000000, 'market_share': 0.3, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok']},
    'ë¦¬ì±” ì˜¤ë¯ˆë ˆí–„ 340g': {'tam': 3000000, 'market_share': 0.5, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok']},
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 500g':  {'tam': 2500000, 'market_share': 0.075, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 900g':  {'tam': 2500000, 'market_share': 0.060, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 500g':  {'tam': 2500000, 'market_share': 0.090, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 900g':  {'tam': 2500000, 'market_share': 0.075, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 500g': {'tam': 2500000, 'market_share': 0.05, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 900g': {'tam': 2500000, 'market_share': 0.02, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ë°”ë‹ë¼ë¼ë–¼ 250mL': {'tam': 15000000, 'market_share': 0.08, 'modifiers': [1.0, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.0, 1.1, 1.1, 1.1, 1.0]},
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ì¹´í˜ë¼ë–¼ 250mL':  {'tam': 15000000, 'market_share': 0.12, 'modifiers': [1.0, 1.1, 1.1, 1.1, 1.1, 1.1, 1.1, 1.0, 1.1, 1.1, 1.1, 1.0]},
    'default': {'tam': 10000000, 'market_share': 0.10, 'modifiers': DEFAULT_MODIFIERS}
}
START_MONTH_INDEX = 6
for product, params in SIMULATION_PARAMS.items():
    original_modifiers = params['modifiers']
    reordered_modifiers = original_modifiers[START_MONTH_INDEX:] + original_modifiers[:START_MONTH_INDEX]
    SIMULATION_PARAMS[product]['modifiers'] = reordered_modifiers

logger.info("âœ… 3-2. SKU íŒŒë¼ë¯¸í„° ì„¤ì • ë° ì›”ë³„ ê°€ì¤‘ì¹˜ ì¬ì •ë ¬ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================================================================
# âœ¨ 4. ë©”ì¸ ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„
# ==============================================================================
try:
    submission_df = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))
    logger.info("âœ… 4. ì œì¶œìš© ë°ì´í„°í”„ë ˆì„ ë¡œë“œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
except FileNotFoundError:
    logger.error(f"â—ï¸ 'sample_submission.csv' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit()

PERSONAS_PER_BATCH = 30
NUM_BATCHES_PER_PRODUCT = 20
MAX_RETRIES_PER_BATCH = 3
submission_filename = os.path.join(PATH, f'submission_final_{timestamp}.csv')

for index, row in submission_df.iterrows():
    product_name = row['product_name']
    logger.info(f"\n==================== [ {product_name} ] íŒë§¤ëŸ‰ ì˜ˆì¸¡ ì‹œì‘ ====================")

    params = SIMULATION_PARAMS.get(product_name, SIMULATION_PARAMS['default'])
    
    # â­ ìˆ˜ì •: í˜ë¥´ì†Œë‚˜ ìƒì„± ë¡œì§ì„ ìºì‹œ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°
    product_personas = []
    
    # íŒŒì¼ëª…ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì œí’ˆëª…ì„ ì•ˆì „í•˜ê²Œ ë³€í™˜
    safe_product_name = sanitize_filename(product_name)
    persona_cache_file = os.path.join(PERSONA_CACHE_PATH, f'{safe_product_name}_personas.json')

    # 1. ìºì‹œ ì‚¬ìš© ëª¨ë“œì¼ ê²½ìš°, íŒŒì¼ ë¡œë“œë¥¼ ë¨¼ì € ì‹œë„
    if not USE_API_TO_GENERATE_PERSONAS and os.path.exists(persona_cache_file):
        try:
            with open(persona_cache_file, 'r', encoding='utf-8') as f:
                product_personas = json.load(f)
            logger.info(f"âœ… [ìºì‹œ ì‚¬ìš©] '{persona_cache_file}' ì—ì„œ í˜ë¥´ì†Œë‚˜ {len(product_personas)}ëª…ì„ ì„±ê³µì ìœ¼ë¡œ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.warning(f"â—ï¸ ìºì‹œ íŒŒì¼ '{persona_cache_file}' ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}. APIë¥¼ í†µí•´ ì¬ìƒì„±ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            product_personas = [] # ì˜¤ë¥˜ ë°œìƒ ì‹œ, ë¦¬ìŠ¤íŠ¸ë¥¼ ë¹„ì›Œ ì•„ë˜ API ë¡œì§ì„ íƒ€ë„ë¡ ìœ ë„

    # 2. í˜ë¥´ì†Œë‚˜ê°€ ë¹„ì–´ìˆì„ ê²½ìš° (ìºì‹œë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê±°ë‚˜, ìºì‹œ íŒŒì¼ì´ ì—†ê±°ë‚˜, ë¡œë“œ ì‹¤íŒ¨ ì‹œ)
    if not product_personas:
        if USE_API_TO_GENERATE_PERSONAS:
            logger.info("ğŸš€ [API ëª¨ë“œ] Gemini APIë¥¼ í†µí•´ í˜ë¥´ì†Œë‚˜ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            for i in range(NUM_BATCHES_PER_PRODUCT):
                for attempt in range(MAX_RETRIES_PER_BATCH):
                    try:
                        prompt = create_product_specific_prompt(product_name, PERSONAS_PER_BATCH)
                        logger.info(f" â³ ë°°ì¹˜ {i+1}/{NUM_BATCHES_PER_PRODUCT} API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt+1})")
                        response = model.generate_content(prompt)
                        
                        json_text = extract_json_from_response(response.text)
                        if not json_text:
                            raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        
                        batch_personas = json.loads(json_text)
                        product_personas.extend(batch_personas)
                        logger.info(f" âœ… ë°°ì¹˜ {i+1} ìƒì„± ì™„ë£Œ! ({len(batch_personas)}ëª… ì¶”ê°€)")
                        time.sleep(20)
                        break
                    except Exception as e:
                        logger.warning(f" â—ï¸ ë°°ì¹˜ {i+1} ì‹œë„ {attempt+1} ì‹¤íŒ¨: {e}")
                        if attempt < MAX_RETRIES_PER_BATCH - 1:
                            logger.info(" 20ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                            time.sleep(20)
                        else:
                            logger.error(f" âŒ ë°°ì¹˜ {i+1} ìƒì„± ìµœì¢… ì‹¤íŒ¨.")
            
            # APIë¡œ ì„±ê³µì ìœ¼ë¡œ ìƒì„± í›„, íŒŒì¼ë¡œ ì €ì¥
            if product_personas:
                try:
                    with open(persona_cache_file, 'w', encoding='utf-8') as f:
                        json.dump(product_personas, f, ensure_ascii=False, indent=4)
                    logger.info(f"ğŸ’¾ [ìºì‹œ ì €ì¥] ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ {len(product_personas)}ëª…ì„ '{persona_cache_file}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    logger.error(f"â—ï¸ í˜ë¥´ì†Œë‚˜ ìºì‹œ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        else: # API ì‚¬ìš© ì•ˆ í•¨ & ìºì‹œ íŒŒì¼ë„ ì—†ëŠ” ê²½ìš°
             logger.warning(f"âš ï¸ [ìºì‹œ ì—†ìŒ] '{persona_cache_file}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ ì œí’ˆì€ ê±´ë„ˆëœë‹ˆë‹¤.")
             logger.warning(f"   (í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ë ¤ë©´ ìŠ¤í¬ë¦½íŠ¸ ìƒë‹¨ì˜ USE_API_TO_GENERATE_PERSONASë¥¼ Trueë¡œ ë³€ê²½í•˜ì„¸ìš”.)")


    # í˜ë¥´ì†Œë‚˜ ìƒì„±ì— ìµœì¢… ì‹¤íŒ¨í•œ ê²½ìš°, í•´ë‹¹ ì œí’ˆì€ 0ìœ¼ë¡œ ì²˜ë¦¬í•˜ê³  ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°
    if not product_personas:
        logger.error(f" ğŸš« í˜ë¥´ì†Œë‚˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. [ {product_name} ] íŒë§¤ëŸ‰ì„ 0ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        submission_df.iloc[index, 1:] = [0] * 12
        continue

    # --- ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ (ê¸°ì¡´ ë¡œì§ê³¼ ê±°ì˜ ë™ì¼) ---
    if product_name in ESTABLISHED_PRODUCTS:
        initial_rate = np.random.uniform(0.4, 0.6)
    else:
        initial_rate = 1.0

    logger.info(f"--- [ {product_name} ] ABM & Bass Model ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ---")
    market_sim = MarketSimulation(
        personas=product_personas,
        tam=params['tam'],
        market_share=params['market_share'],
        modifiers=params['modifiers'],
        initial_adoption_rate=initial_rate
    )
    
    monthly_sales = market_sim.run_simulation(months=12)
    
    if product_name in NEW_PRODUCT_LAUNCH_DATES:
        launch_year, launch_month = NEW_PRODUCT_LAUNCH_DATES[product_name]
        logger.info(f"   - âš ï¸ ì‹ ì œí’ˆ ({launch_year}ë…„ {launch_month}ì›” ì¶œì‹œ). ì¶œì‹œì¼ ì´ì „ íŒë§¤ëŸ‰ì„ 0ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
        
        for month_index in range(12):
            current_month = 7 + month_index
            current_year = 2024
            if current_month > 12:
                current_month -= 12
                current_year = 2025
            
            is_before_launch = (current_year < launch_year) or \
                               (current_year == launch_year and current_month < launch_month)

            if is_before_launch:
                monthly_sales[month_index] = 0

    submission_df.iloc[index, 1:] = monthly_sales
    logger.info(f"ğŸ“ˆ [ {product_name} ] 12ê°œì›” íŒë§¤ëŸ‰ ì˜ˆì¸¡ ì™„ë£Œ!")
    logger.info(f"   - ìµœì¢… ì˜ˆì¸¡ íŒë§¤ëŸ‰: {monthly_sales}")

    # â­ ìˆ˜ì •: ë§ˆì§€ë§‰ ì œí’ˆ ì‹¤í–‰ í›„ì—ëŠ” ëŒ€ê¸°í•˜ì§€ ì•Šë„ë¡ ì¡°ê±´ ì¶”ê°€
    if index < len(submission_df) - 1:
        # API ëª¨ë“œì¼ ë•ŒëŠ” 60ì´ˆ, ìºì‹œ ëª¨ë“œì¼ë•ŒëŠ” 1ì´ˆ ëŒ€ê¸°
        wait_time = 60 if USE_API_TO_GENERATE_PERSONAS else 1
        logger.info(f"ğŸ•’ ë‹¤ìŒ ì œí’ˆ ë¶„ì„ ì „ {wait_time}ì´ˆê°„ ëŒ€ê¸°í•©ë‹ˆë‹¤...")
        time.sleep(wait_time)

# --- ìµœì¢… íŒŒì¼ ì €ì¥ ---
submission_df.to_csv(submission_filename, index=False, encoding='utf-8-sig')
logger.info(f"\n\nğŸ‰ğŸ‰ğŸ‰ ëª¨ë“  ì œí’ˆì˜ ì‹œë®¬ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
logger.info(f"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ '{submission_filename}' ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
logger.info(f"âœ… ìƒì„¸ ë¡œê·¸ëŠ” '{log_filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")