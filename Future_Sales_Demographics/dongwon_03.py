# ==============================================================================
# ğŸ“ ì‚¬ì „ ì¤€ë¹„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° API í‚¤ ì„¤ì •
# ==============================================================================
import google.generativeai as genai
import pandas as pd
import json
import os
import time
import re
import logging # ğŸªµ ë¡œê¹… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸

# âœ¨ ê²½ë¡œ ì„¤ì •ì€ ê·¸ëŒ€ë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
PATH = './data/dongwon/'
os.makedirs(PATH, exist_ok=True)

# ğŸªµ ======================= [ì‹ ê·œ] ë¡œê±° ì„¤ì • ======================= ğŸªµ
# íŒŒì¼ëª…ì— ì‚¬ìš©í•  íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë¨¼ì € ìƒì„±
timestamp = time.strftime("%Y%m%d_%H%M%S")

# ë¡œê±° ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í¬ë§·í„° ìƒì„±
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

# ìŠ¤íŠ¸ë¦¼ í•¸ë“¤ëŸ¬ (ì½˜ì†” ì¶œë ¥)
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(formatter)
logger.addHandler(stream_handler)

# íŒŒì¼ í•¸ë“¤ëŸ¬ (íŒŒì¼ ì¶œë ¥)
log_filename = os.path.join(PATH, f'v3_log_{timestamp}.log')
file_handler = logging.FileHandler(log_filename, encoding='utf-8')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

logger.info("âœ… ë¡œê¹… ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì½˜ì†”ê³¼ íŒŒì¼ì— ë¡œê·¸ê°€ ê¸°ë¡ë©ë‹ˆë‹¤.")
# ğŸªµ =============================================================== ğŸªµ

# [ì¤‘ìš”] ì‚¬ìš©ìì˜ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
try:
    # -------------------------------------------------------------------------
    genai.configure(api_key="") # <--- ì—¬ê¸°ì— ì‹¤ì œ API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    # -------------------------------------------------------------------------
    model = genai.GenerativeModel('models/gemini-2.0-flash')
    logger.info("âœ… Gemini API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    logger.error(f"â—ï¸ API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")


# í—¬í¼ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼)
def extract_json_from_response(text):
    match = re.search(r'\[.*\]', text, re.DOTALL)
    if match:
        return match.group(0)
    return None

# ==============================================================================
# âœ¨ 1. [ì‹ ê·œ] ì œí’ˆë³„ í˜ë¥´ì†Œë‚˜ ìƒì„±ì„ ìœ„í•œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜
# ==============================================================================
def create_product_specific_prompt(product_name, num_personas=30): # ğŸªµ ê¸°ë³¸ê°’ 30ìœ¼ë¡œ ìˆ˜ì •
    """
    ì œí’ˆ ì´ë¦„ê³¼ íŠ¹ì„±ì„ ê¸°ë°˜ìœ¼ë¡œ ë§ì¶¤í˜• í˜ë¥´ì†Œë‚˜ ìƒì„± í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    target_customer_profile = "ì¼ë°˜ì ì¸ ëŒ€í•œë¯¼êµ­ ì†Œë¹„ì" # ê¸°ë³¸ê°’

    # --- ì œí’ˆêµ°ë³„ íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„ ì •ì˜ ---
    if 'í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸' in product_name:
        target_customer_profile = "20-40ëŒ€ ì—¬ì„±ìœ¼ë¡œ, ê±´ê°•ê³¼ ìê¸°ê´€ë¦¬ì— ê´€ì‹¬ì´ ë§ê³ , ì†Œë“ ìˆ˜ì¤€ì€ ì¤‘ìƒ ì´ìƒì¸ 1ì¸ ê°€êµ¬. ì£¼ë¡œ ì˜¨ë¼ì¸ ì±„ë„ì„ í†µí•´ ê±´ê°•ì‹í’ˆì„ êµ¬ë§¤í•˜ëŠ” ê²½í–¥ì´ ìˆìŒ."
    elif 'ë§›ì°¸' in product_name:
        target_customer_profile = "10-30ëŒ€ ë‚¨ë…€ë¡œ, í¸ì˜ì„±ê³¼ ìƒˆë¡œìš´ ë§›ì„ ì¶”êµ¬í•˜ë©° ìœ íŠœë¸Œ, ì¸ìŠ¤íƒ€ê·¸ë¨ ë“± ì†Œì…œ ë¯¸ë””ì–´ì— ìµìˆ™í•¨. í¸ì˜ì ì´ë‚˜ ì˜¨ë¼ì¸ì—ì„œ ê°„í¸í•˜ê²Œ ì‹ì‚¬ë¥¼ í•´ê²°í•˜ë ¤ëŠ” 1ì¸ ê°€êµ¬ í•™ìƒ ë° ì§ì¥ì¸."
        if 'ë§¤ì½¤' in product_name:
            target_customer_profile += " íŠ¹íˆ ë§¤ìš´ë§›ì„ ì„ í˜¸í•˜ëŠ” ê²½í–¥ì´ ëšœë ·í•¨."
    elif 'ë¦¬ì±”' in product_name:
        target_customer_profile = "30-40ëŒ€ ì£¼ë¶€ë¡œ, 3ì¸ ì´ìƒ ê°€êµ¬ì˜ ì‹ì‚¬ë¥¼ ì±…ì„ì§€ê³  ìˆìŒ. ëŒ€í˜•ë§ˆíŠ¸ì—ì„œ ì¥ì„ ë³´ë©°, ëª…ì ˆ ë“± íŠ¹ë³„í•œ ë‚ ì— ê°€ì¡±ì„ ìœ„í•œ ìš”ë¦¬ë¥¼ ì¤€ë¹„í•˜ëŠ” ê²ƒì„ ì¤‘ìš”í•˜ê²Œ ìƒê°í•¨."
    elif 'ì°¸ì¹˜ì•¡' in product_name:
        target_customer_profile = "ìš”ë¦¬ì— ê´€ì‹¬ì´ ë§ì€ 30-50ëŒ€ ì£¼ë¶€ ë˜ëŠ” 1ì¸ ê°€êµ¬. ì§‘ë°¥ì„ ì„ í˜¸í•˜ë©°, ìŒì‹ì˜ ê¹Šì€ ë§›ì„ ë‚´ê¸° ìœ„í•œ ì¡°ë¯¸ë£Œì— íˆ¬ìë¥¼ ì•„ë¼ì§€ ì•ŠìŒ. ëŒ€í˜•ë§ˆíŠ¸ì™€ ì˜¨ë¼ì¸ ì±„ë„ì„ ëª¨ë‘ ì´ìš©í•¨."
        if 'ì§„' in product_name or 'í”„ë¦¬ë¯¸ì—„' in product_name:
            target_customer_profile += " íŠ¹íˆ ìš”ë¦¬ ì‹¤ë ¥ì´ ë›°ì–´ë‚˜ê³ , ì†Œë“ ìˆ˜ì¤€ì´ ë†’ì•„ í”„ë¦¬ë¯¸ì—„ ì œí’ˆì„ ì„ í˜¸í•˜ëŠ” ë¯¸ì‹ê°€ì  ì„±í–¥ì„ ë³´ì„."
    elif 'ì†Œí™”ê°€ ì˜ë˜ëŠ”' in product_name:
        target_customer_profile = "ìœ ë‹¹ë¶ˆë‚´ì¦ì´ ìˆê±°ë‚˜ ì†Œí™” ê±´ê°•ì— ì‹ ê²½ ì“°ëŠ” 20-50ëŒ€ ì§ì¥ì¸. ê±´ê°•ì„ ìœ„í•´ ì¼ë°˜ ìœ ì œí’ˆ ëŒ€ì‹  ë½í† í”„ë¦¬ ì œí’ˆì„ ì„ íƒí•˜ë©°, ì¶œê·¼ê¸¸ì´ë‚˜ ì ì‹¬ì‹œê°„ì— í¸ì˜ì ì—ì„œ ìì£¼ êµ¬ë§¤í•¨."
        if 'ë°”ë‹ë¼ë¼ë–¼' in product_name:
            target_customer_profile += " ë‹¨ë§›ì„ ì„ í˜¸í•˜ëŠ” ì Šì€ ì¸µì˜ ë¹„ì¤‘ì´ ìƒëŒ€ì ìœ¼ë¡œ ë†’ìŒ."

    # ğŸªµ íƒ€ê²Ÿ í”„ë¡œí•„ì„ ë¡œê·¸ë¡œ ê¸°ë¡
    logger.info(f"  - íƒ€ê²Ÿ í”„ë¡œí•„ ì„¤ì •: {target_customer_profile}")

    prompt = f"""
    ë‹¹ì‹ ì€ íŠ¹ì • ì œí’ˆì˜ í•µì‹¬ êµ¬ë§¤ ê³ ê° í˜ë¥´ì†Œë‚˜ë¥¼ ìƒì„±í•˜ëŠ” ë§ˆì¼€íŒ… ë¶„ì„ AIì…ë‹ˆë‹¤.

    [ì§€ì‹œì‚¬í•­]
    1.  **ì„ë¬´**: ì•„ë˜ [ì œí’ˆ ì •ë³´]ì— ëª…ì‹œëœ ì œí’ˆì„ êµ¬ë§¤í•  ê°€ëŠ¥ì„±ì´ ë§¤ìš° ë†’ì€ **í•µì‹¬ ê³ ê° í˜ë¥´ì†Œë‚˜ {num_personas}ê°œ**ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    2.  **í•µì‹¬ ì¡°ê±´**: ìƒì„±ë˜ëŠ” í˜ë¥´ì†Œë‚˜ëŠ” ì•„ë˜ [íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„]ì˜ íŠ¹ì„±ì„ ì§‘ì¤‘ì ìœ¼ë¡œ ë°˜ì˜í•´ì•¼ í•©ë‹ˆë‹¤. í˜ë¥´ì†Œë‚˜ì˜ ëª¨ë“  ì†ì„±ì€ ì´ í”„ë¡œí•„ê³¼ ë…¼ë¦¬ì ìœ¼ë¡œ ê°•ë ¥í•˜ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    3.  **ì¶œë ¥**: ë‹¤ë¥¸ ì„¤ëª… ì—†ì´, [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]ë¥¼ ì™„ë²½íˆ ë”°ë¥´ëŠ” ë‹¨ì¼ JSON ë°°ì—´ë§Œ ë°˜í™˜í•˜ì„¸ìš”.

    [ì œí’ˆ ì •ë³´]
    - ì œí’ˆëª…: "{product_name}"

    [íƒ€ê²Ÿ ê³ ê° í”„ë¡œí•„]
    - {target_customer_profile}

    [ì†ì„± ê°€ì´ë“œ]
    - `age`: "10ëŒ€", "20ëŒ€", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"
    - `gender`: "ë‚¨ì„±", "ì—¬ì„±"
    - `occupation`: "ì§ì¥ì¸", "í•™ìƒ", "ì£¼ë¶€", "í”„ë¦¬ëœì„œ", "ìì˜ì—…ì", "ë¬´ì§", "ì€í‡´"
    - `income_level`: "ìƒ", "ì¤‘ìƒ", "ì¤‘", "ì¤‘í•˜", "í•˜"
    - `household_size`: "1ì¸ ê°€êµ¬", "2ì¸ ê°€êµ¬", "3ì¸ ê°€êµ¬", "4ì¸ ê°€êµ¬ ì´ìƒ"
    - `lifestyle`: "ê±´ê°•ì§€í–¥", "ìê¸°ê´€ë¦¬", "í¸ì˜ì„±ì¶”êµ¬", "ê°€ì„±ë¹„ì¤‘ì‹œ", "íŠ¸ë Œë“œì¶”êµ¬", "ìš”ë¦¬ì• í˜¸ê°€", "ì§‘ë°¥ì„ í˜¸", "ë¯¸ì‹ê°€"
    - `media_consumption`: ["YouTube", "Instagram", "TV", "ì»¤ë®¤ë‹ˆí‹°ì‚¬ì´íŠ¸"] ë“±
    - `price_sensitivity`: "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
    - `brand_loyalty`: "ë†’ìŒ", "ì¤‘ê°„", "ë‚®ìŒ"
    - `dietary_preferences`: "ê³ ë‹¨ë°±", "ì €ì¹¼ë¡œë¦¬", "ìœ ë‹¹ë¶ˆë‚´ì¦ì¼€ì–´", "ì†Œí™”í¸í•œìŒì‹ì„ í˜¸", "ë§¤ìš´ë§›ì„ í˜¸" ë“±
    - `shopping_channel`: "ëŒ€í˜•ë§ˆíŠ¸", "ì˜¨ë¼ì¸", "í¸ì˜ì ", "ë°±í™”ì "

    [ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
    [
      {{
        "persona_id": "P00001", "attributes": {{"age": "30ëŒ€", "gender": "ì—¬ì„±", "occupation": "ì§ì¥ì¸", "income_level": "ì¤‘ìƒ", "household_size": "1ì¸ ê°€êµ¬", "lifestyle": "ê±´ê°•ì§€í–¥", "media_consumption": ["YouTube", "Instagram"], "price_sensitivity": "ì¤‘ê°„", "brand_loyalty": "ë‚®ìŒ", "dietary_preferences": "ê³ ë‹¨ë°±", "shopping_channel": "ì˜¨ë¼ì¸"}}, "purchase_probability": 0.85, "base_purchase_frequency_per_month": 4.0, "monthly_propensity_modifier": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
      }}
    ]
    """
    return prompt

logger.info("âœ… 1. ì œí’ˆë³„ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± í•¨ìˆ˜ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ğŸªµ ======================= [ì‹ ê·œ] í˜ë¥´ì†Œë‚˜ ë¶„ì„ ë¡œê·¸ í•¨ìˆ˜ ======================= ğŸªµ
def log_persona_summary(df, product_name):
    if df.empty:
        return
    logger.info(f"--- [ {product_name} ] í˜ë¥´ì†Œë‚˜ ë¶„ì„ ê²°ê³¼ ---")
    logger.info(f"  - ì´ {len(df)}ê°œì˜ í˜ë¥´ì†Œë‚˜ ìƒì„±ë¨")
    
    # êµ¬ë§¤ í–‰ë™ ê´€ë ¨ ë¡œê·¸
    avg_prob = df['purchase_probability'].mean()
    avg_freq = df['base_purchase_frequency_per_month'].mean()
    logger.info(f"  - í‰ê·  êµ¬ë§¤ í™•ë¥ : {avg_prob:.2f}")
    logger.info(f"  - í‰ê·  ì›” êµ¬ë§¤ ë¹ˆë„: {avg_freq:.2f}")

    # ì£¼ìš” ì†ì„± ë¶„í¬ ë¡œê·¸ (ìƒìœ„ 3ê°œ)
    key_attributes = ['age', 'lifestyle', 'shopping_channel', 'occupation']
    for attr in key_attributes:
        if attr in df.columns:
            dist = df[attr].value_counts(normalize=True).nlargest(3) * 100
            dist_str = ", ".join([f"{idx} {val:.1f}%" for idx, val in dist.items()])
            logger.info(f"  - '{attr}' ë¶„í¬: {dist_str}")
    logger.info("----------------------------------------------------")
# ğŸªµ =========================================================================== ğŸªµ

# ==============================================================================
# âœ¨ 2. ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„° ì •ì˜ (ê¸°ì¡´ê³¼ ë™ì¼)
# ==============================================================================
HOLIDAY_MODIFIERS = {
    'seollal_chuseok': [1.8, 5.5, 1.0, 0.9, 1.0, 1.1, 1.2, 2.5, 6.5, 1.0, 1.0, 1.1],
    'seollal_chuseok_sub': [1.3, 3.0, 1.0, 1.1, 1.2, 1.1, 1.2, 1.8, 3.5, 1.1, 1.0, 1.3]
}
DEFAULT_MODIFIERS = [1.0] * 12
SIMULATION_PARAMS = {
    'ë´ë§ˆí¬ í•˜ì´ê·¸ë¦­ìš”ê±°íŠ¸ 400g': {'tam': 600000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.2, 1.4, 1.4, 1.3, 1.2, 1.2, 0.9, 0.8, 0.7, 0.7]},
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 135g': {'tam': 2000000, 'market_share': 0.07, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë™ì›ë§›ì°¸ ê³ ì†Œì°¸ê¸°ë¦„ 90g':  {'tam': 2000000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 135g': {'tam': 2000000, 'market_share': 0.05, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë™ì›ë§›ì°¸ ë§¤ì½¤ì°¸ê¸°ë¦„ 90g':  {'tam': 2000000, 'market_share': 0.03, 'modifiers': [1.2, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.2, 1.2, 1.0, 1.1, 1.2]},
    'ë¦¬ì±” ì˜¤ë¯ˆë ›í–„ 200g': {'tam': 3000000, 'market_share': 0.3, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok']},
    'ë¦¬ì±” ì˜¤ë¯ˆë ›í–„ 340g': {'tam': 3000000, 'market_share': 0.5, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok']},
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 500g':  {'tam': 250000, 'market_share': 0.025, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ìˆœ 900g':  {'tam': 250000, 'market_share': 0.020, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 500g':  {'tam': 250000, 'market_share': 0.030, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ë™ì›ì°¸ì¹˜ì•¡ ì§„ 900g':  {'tam': 250000, 'market_share': 0.025, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 500g': {'tam': 250000, 'market_share': 0.015, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'í”„ë¦¬ë¯¸ì—„ ë™ì›ì°¸ì¹˜ì•¡ 900g': {'tam': 250000, 'market_share': 0.010, 'modifiers': HOLIDAY_MODIFIERS['seollal_chuseok_sub']},
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ë°”ë‹ë¼ë¼ë–¼ 250mL': {'tam': 2000000, 'market_share': 0.09, 'modifiers': [1.0, 1.1, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1, 1.1]},
    'ì†Œí™”ê°€ ì˜ë˜ëŠ” ìš°ìœ ë¡œ ë§Œë“  ì¹´í˜ë¼ë–¼ 250mL':   {'tam': 2000000, 'market_share': 0.12, 'modifiers': [1.0, 1.1, 1.2, 1.1, 1.0, 1.0, 1.0, 1.0, 1.1, 1.1, 1.1, 1.1]},
    'default': {'tam': 1000000, 'market_share': 0.10, 'modifiers': DEFAULT_MODIFIERS}
}
START_MONTH_INDEX = 6
for product, params in SIMULATION_PARAMS.items():
    original_modifiers = params['modifiers']
    reordered_modifiers = original_modifiers[START_MONTH_INDEX:] + original_modifiers[:START_MONTH_INDEX]
    SIMULATION_PARAMS[product]['modifiers'] = reordered_modifiers

logger.info("âœ… 2. SKUë³„ ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„° ì„¤ì • ë° ì›”ë³„ ê°€ì¤‘ì¹˜ ì¬ì •ë ¬ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# ==============================================================================
# âœ¨ 3. ì œí’ˆë³„ í˜ë¥´ì†Œë‚˜ ìƒì„± ë° íŒë§¤ëŸ‰ ì‹œë®¬ë ˆì´ì…˜ (ë¡œê¹… ê°•í™”)
# ==============================================================================
try:
    submission_df = pd.read_csv(os.path.join(PATH, 'sample_submission.csv'))
    logger.info("âœ… 3. ì œì¶œìš© ë°ì´í„°í”„ë ˆì„ ë¡œë“œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤. ì´ì œ ì‹œë®¬ë ˆì´ì…˜ì„ ì‹œì‘í•©ë‹ˆë‹¤.")
except FileNotFoundError as e:
    logger.error(f"â—ï¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}. 'sample_submission.csv' íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    exit()

# ì‹œë®¬ë ˆì´ì…˜ ì„¤ì •
PERSONAS_PER_BATCH = 30
NUM_BATCHES_PER_PRODUCT = 4
MAX_RETRIES_PER_BATCH = 4
submission_filename = os.path.join(PATH, f'my_submission_v3_{timestamp}.csv')

# --- ë©”ì¸ ì‹œë®¬ë ˆì´ì…˜ ë£¨í”„ ---
for index, row in submission_df.iterrows():
    product_name = row['product_name']
    logger.info(f"\n==================== [ {product_name} ] íŒë§¤ëŸ‰ ì˜ˆì¸¡ ì‹œì‘ ====================")

    params = SIMULATION_PARAMS.get(product_name, SIMULATION_PARAMS['default'])
    
    product_personas = []
    for i in range(NUM_BATCHES_PER_PRODUCT):
        for attempt in range(MAX_RETRIES_PER_BATCH):
            try:
                prompt = create_product_specific_prompt(product_name, PERSONAS_PER_BATCH)
                logger.info(f" â³ ë°°ì¹˜ {i+1}/{NUM_BATCHES_PER_PRODUCT} API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt+1})")
                response = model.generate_content(prompt)
                
                json_text = extract_json_from_response(response.text)
                if not json_text:
                    raise ValueError("ì‘ë‹µì—ì„œ JSONì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                batch_personas = json.loads(json_text)
                product_personas.extend(batch_personas)
                logger.info(f" âœ… ë°°ì¹˜ {i+1} ìƒì„± ì™„ë£Œ! ({len(batch_personas)}ëª… ì¶”ê°€)")
                time.sleep(20)
                break

            except Exception as e:
                logger.warning(f" â—ï¸ ë°°ì¹˜ {i+1} ì‹œë„ {attempt+1} ì‹¤íŒ¨: {e}")
                if attempt < MAX_RETRIES_PER_BATCH - 1:
                    logger.info(" 20ì´ˆ í›„ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                    time.sleep(20)
                else:
                    logger.error(f" âŒ ë°°ì¹˜ {i+1} ìƒì„± ìµœì¢… ì‹¤íŒ¨.")
    
    if not product_personas:
        logger.error(f" ğŸš« í˜ë¥´ì†Œë‚˜ ìƒì„±ì— ì‹¤íŒ¨í•˜ì—¬ [ {product_name} ]ì˜ íŒë§¤ëŸ‰ì„ 0ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        submission_df.iloc[index, 1:] = [0] * 12
        continue

    personas_df_product = pd.DataFrame(product_personas)
    attributes_df_product = pd.json_normalize(personas_df_product['attributes'])
    personas_df_product = pd.concat([personas_df_product.drop('attributes', axis=1), attributes_df_product], axis=1)

    # ğŸªµ ìƒì„±ëœ í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì„±ì„ ë¡œê·¸ë¡œ ê¸°ë¡
    log_persona_summary(personas_df_product, product_name)

    logger.info(f"--- [ {product_name} ] ì›”ë³„ íŒë§¤ëŸ‰ ê³„ì‚° ì‹œì‘ ---")
    monthly_sales = []
    num_personas = len(personas_df_product)
    
    # ì˜ˆì¸¡ ê¸°ê°„(7ì›”~6ì›”)ì— ë§ì¶° ì›” ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    month_labels = [f"{m}ì›”" for m in list(range(7, 13)) + list(range(1, 7))]

    for month_index in range(12):
        month_modifier = params['modifiers'][month_index]
        
        # ğŸªµ ê³„ì‚° ê³¼ì •ì„ ë‹¨ê³„ë³„ë¡œ ë¶„í•´í•˜ì—¬ ë¡œê¹…
        base_purchase_points = (
            personas_df_product['purchase_probability'] *
            personas_df_product['base_purchase_frequency_per_month']
        )
        total_purchase_points = (base_purchase_points * month_modifier).sum()
        
        avg_points_per_persona = total_purchase_points / num_personas if num_personas > 0 else 0
        
        final_sales = avg_points_per_persona * params['tam'] * params['market_share']
        monthly_sales.append(int(final_sales))
        
        # ğŸªµ ê³„ì‚° ë¡œê·¸ ì¶œë ¥
        log_msg = (
            f"  - [{month_labels[month_index]:>3s}] ê³„ì‚°: "
            f"í˜ë¥´ì†Œë‚˜ í‰ê·  êµ¬ë§¤ë ¥({avg_points_per_persona / month_modifier:.2f}) "
            f"x ì›” ê³„ìˆ˜({month_modifier:.2f}) "
            f"x TAM({params['tam']}) "
            f"x ì ìœ ìœ¨({params['market_share']:.3f}) "
            f"= ìµœì¢… íŒë§¤ëŸ‰: {int(final_sales)}"
        )
        logger.info(log_msg)

    submission_df.iloc[index, 1:] = monthly_sales
    logger.info(f"ğŸ“ˆ [ {product_name} ] 12ê°œì›” íŒë§¤ëŸ‰ ì˜ˆì¸¡ ì™„ë£Œ!")

    if index < len(submission_df) - 1:
        logger.info("ğŸ•’ ë‹¤ìŒ ì œí’ˆ ë¶„ì„ ì „, API í• ë‹¹ëŸ‰ ì¤€ìˆ˜ë¥¼ ìœ„í•´ 60ì´ˆê°„ ëŒ€ê¸°í•©ë‹ˆë‹¤...")
        time.sleep(60)

# --- ìµœì¢… íŒŒì¼ ì €ì¥ ---
submission_df.to_csv(submission_filename, index=False)
logger.info(f"\n\nğŸ‰ğŸ‰ğŸ‰ ëª¨ë“  ì œí’ˆì˜ ì‹œë®¬ë ˆì´ì…˜ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
logger.info(f"âœ… ìµœì¢… ì œì¶œ íŒŒì¼ '{submission_filename}' ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
logger.info(f"âœ… ìƒì„¸ ë¡œê·¸ëŠ” '{log_filename}' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

print("\n[ ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ (ìƒìœ„ 5ê°œ ì œí’ˆ) ]")
print(submission_df.head())